# -*- coding: utf-8 -*-
"""train_fix_jn_RES

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zf4nfDdGmbwTV-IJeDHp6SQjsD_iZ38U
"""

# -*- coding: utf-8 -*-
"""
Created on Wed Jul  8 15:42:46 2020
@author: edwin.p.alegre
"""

import os

abspath = os.path.abspath(__file__)
dname = os.path.dirname(abspath)
os.chdir(dname)

import model_resunet_jn  # new model attempt
import numpy as np
import tensorflow as tf
from math import floor
from tqdm import tqdm
from skimage.io import imread
import matplotlib.pyplot as plt
from tensorflow.keras.callbacks import LearningRateScheduler
from tensorflow.keras.optimizers import Adam
from tensorflow_addons.metrics import F1Score
import random
import scipy.misc
from PIL import Image
import shutil
from utils import DatasetLoad, relaxed_metrics
from utils_fix_jn import imgstitch
import  model_resunet_ec 

########################### LEARNING RATE SCHEDULER ###########################

def schedlr(epoch, lr):
    #new_lr = 0.001 * (0.1)**(floor(epoch/10))
    return 0.001
    return new_lr

############################### HYPERPARAMETERS ###############################

IMG_SIZE = 224
BATCH = 8
EPOCHS = 30

################################### DATASET ###################################

train_dataset = r'/projectnb/ec523/projects/Proj_road_segment_fix/EE8204-ResUNet/dataset/samples_train'
test_dataset = r'/projectnb/ec523/projects/Proj_road_segment_fix/EE8204-ResUNet/dataset/test_patch'

_, test_fol, _ = next(os.walk(test_dataset))

if os.path.exists("preprocessed_data.npz"):
    data = np.load("preprocessed_data.npz", allow_pickle=True)
    X_train = data["X_train"]
    Y_train = data["Y_train"]
    X_test = data["X_test"]
    Y_test = data["Y_test"]
    X_val = data["X_val"]
    Y_val = data["Y_val"]
else:
    X_train, Y_train, X_test, Y_test, X_val, Y_val = DatasetLoad(train_dataset, test_dataset)
    np.savez_compressed("preprocessed_data.npz",
                        X_train=X_train, Y_train=Y_train,
                        X_test=X_test, Y_test=Y_test,
                        X_val=X_val, Y_val=Y_val)

################################ RESUNET ################################

smooth = 1e-6

def dice_coef(y_true, y_pred):
    y_true_f = tf.reshape(y_true, [tf.shape(y_true)[0], -1])
    y_pred_f = tf.reshape(y_pred, [tf.shape(y_pred)[0], -1])
    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=1)
    return tf.reduce_mean((2. * intersection + smooth) /
                          (tf.reduce_sum(y_true_f, axis=1) + tf.reduce_sum(y_pred_f, axis=1) + smooth))

def dice_coef_loss(y_true, y_pred):
    return 1.0 - dice_coef(y_true, y_pred)

optimizer = Adam()
precision = tf.keras.metrics.Precision()
recall = tf.keras.metrics.Recall()
f1 = F1Score(num_classes=2, name='f1', average='micro', threshold=0.4)

# Build ResUNet
model = model_resunet_ec.ResUNet((IMG_SIZE, IMG_SIZE, 3))
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy', precision, recall, f1])
model.summary()

checkpoint_path = os.path.join(dname, 'models_resunet_bce_loss_2', 'resunet.{epoch:02d}-{f1:.2f}.hdf5')
checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1, save_best_only=False)

callbacks = [
    tf.keras.callbacks.EarlyStopping(patience=5, monitor='val_loss'),
    tf.keras.callbacks.TensorBoard(log_dir='logs'),
    LearningRateScheduler(schedlr, verbose=1),
    checkpoint
]

print("Y_train shape:", Y_train.shape, "dtype:", Y_train.dtype, "min:", np.min(Y_train), "max:", np.max(Y_train))

# Train

history = model.fit(
    X_train, Y_train,
    validation_split=0.1,
    batch_size=BATCH,
    epochs=EPOCHS,
    callbacks=callbacks
)
'''
latest_checkpoint = r'models_resunet_bce_loss_2/resunet.16-0.92.hdf5'
model = tf.keras.models.load_model(latest_checkpoint)
history = model.fit(X_train, Y_train, validation_split=0.1, batch_size=BATCH, epochs=16, callbacks=callbacks, initial_epoch=16)
'''
########################### PREDICTION AND RESULTS ############################

if os.path.isdir(r'results_resunet_bce_loss_2'):
    shutil.rmtree('results_resunet_bce_loss_2')

if os.path.isdir(r'results_resunet_bce_loss_2') == False:
    os.mkdir('results_resunet_bce_loss_2')

# Prepare test dataset
_, test_fol, _ = next(os.walk(test_dataset))
_, _, test_files = next(os.walk(os.path.join(test_dataset, test_fol[0], 'image')))
test_imgs = len(test_files)

X_test = {}
Y_test = {}

for folder in test_fol:
    X_test[folder] = np.zeros((len(test_files), IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8)
    Y_test[folder] = np.zeros((len(test_files), IMG_SIZE, IMG_SIZE, 1), dtype=bool)

for folder in test_fol:
    test_path = os.path.join(test_dataset, folder)
    for n, id_ in tqdm(enumerate(test_files), total=len(test_files)):
        X_test[folder][n] = imread(os.path.join(test_path, 'image', f"{id_}"))
        mask = np.zeros((IMG_SIZE, IMG_SIZE, 1), dtype=bool)
        for _ in next(os.walk(os.path.join(test_path, 'mask'))):
            mask_ = imread(os.path.join(test_path, 'mask', f"{id_}"))
            mask_ = np.expand_dims(mask_, axis=-1)
            mask = np.maximum(mask, mask_)
        Y_test[folder][n] = mask

for i in test_fol:
    save_dir = os.path.join('results_resunet_bce_loss_2', str(i))
    os.mkdir(save_dir)

    pred_test = model.predict(X_test[i], verbose=1)
    pred_test_mask = (pred_test > 0.4).astype(np.uint8)

    for n, fname in enumerate(test_files):
        outputmask = np.squeeze(pred_test_mask[n] * 255)
        saveimg = Image.fromarray(outputmask.astype(np.uint8), 'L')
        saveimg.save(os.path.join(save_dir, fname), 'PNG')

for i in test_fol:
    results_dir = os.path.join('results_resunet_bce_loss_2', str(i))
    imgstitch(results_dir)

print("\nEvaluating model on the test set...")

X_test_flat = np.concatenate([X_test[k] for k in X_test], axis=0)
Y_test_flat = np.concatenate([Y_test[k] for k in Y_test], axis=0)

results = model.evaluate(X_test_flat, Y_test_flat, batch_size=8, verbose=1)

metric_names = model.metrics_names
for name, value in zip(metric_names, results):
    print(f"{name}: {value:.4f}")

all_precisions = []
all_recalls = []

for folder in test_fol:
    print(f"Evaluating relaxed metrics on test folder: {folder}")

    preds = model.predict(X_test[folder], verbose=1)
    preds_binary = (preds > 0.4).astype(np.uint8)

    for i in range(len(preds_binary)):
        pred_mask = np.squeeze(preds_binary[i])
        true_mask = np.squeeze(Y_test[folder][i])

        prec, rec = relaxed_metrics(pred_mask, true_mask, slack=3)
        all_precisions.append(prec)
        all_recalls.append(rec)

avg_relaxed_precision = np.mean(all_precisions)
avg_relaxed_recall = np.mean(all_recalls)

print(f"\nRelaxed Precision (ρ=3): {avg_relaxed_precision:.4f}")
print(f"Relaxed Recall (ρ=3): {avg_relaxed_recall:.4f}")

# Plotting
epochs = range(1, len(history.history['loss']) + 1)
train_loss = history.history['loss']
val_loss = history.history['val_loss']
train_f1 = history.history.get('f1')  # Might be 'f1' depending on TensorFlow version
val_f1 = history.history.get('val_f1')

plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.plot(epochs, train_loss, 'b-', label='Train Loss')
plt.plot(epochs, val_loss, 'r-', label='Val Loss')
plt.title('Loss over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(epochs, train_f1, 'b-', label='Train F1')
plt.plot(epochs, val_f1, 'r-', label='Val F1')
plt.title('F1 Score over Epochs')
plt.xlabel('Epoch')
plt.ylabel('F1 Score')
plt.legend()

plt.tight_layout()
plt.savefig('loss_and_f1_resunet_bce_loss_2.png')
plt.show()